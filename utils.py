# --- START OF FILE utils.py ---

from langchain.text_splitter import RecursiveCharacterTextSplitter
import pandas as pd
import re # Added for clean_csv regex
import traceback # For detailed error logging

def preprocess_text(text):
    """Clean text by removing extra spaces and normalizing line breaks."""
    if not isinstance(text, str): return ""
    # Replace multiple spaces/tabs with a single space
    text = re.sub(r'\s+', ' ', text).strip()
    # You might want to retain paragraph breaks (double newlines) if structure is important
    # text = re.sub(r'\n\s*\n', '\n\n', text) # Example: Normalize paragraph breaks
    return text

def chunk_text(text, chunk_size=1000, chunk_overlap=100):
    """Split text into smaller chunks using RecursiveCharacterTextSplitter."""
    if not isinstance(text, str) or not text.strip():
        return []
    try:
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", ". ", ", ", " ", ""], # Common separators
            add_start_index=False # Can be useful for debugging if needed
        )
        chunks = text_splitter.split_text(text)
        # Filter out any potentially empty chunks after splitting
        return [chunk for chunk in chunks if chunk.strip()]
    except Exception as e:
         print(f"Error during text chunking: {e}")
         traceback.print_exc()
         return [] # Return empty list on error


def clean_csv(file_path):
    """
    Cleans the CSV file extracted from the analysis table.
    Assumes the first row is the header after potential title row.

    Args:
        file_path (str): Path to the raw CSV file generated by save_table.

    Returns:
        pd.DataFrame: Cleaned DataFrame, or empty DataFrame if cleaning fails.
    """
    print(f"--- Starting CSV Cleaning for: {file_path} ---")
    try:
        # Read CSV, assuming the first row is the header
        # Skip blank lines during read
        df = pd.read_csv(file_path, header=0, skip_blank_lines=True)

        # --- Column Name Cleaning ---
        print(f"--- Raw CSV Read (Head) ---\n{df.head()}") # Log head
        print(f"Raw CSV Columns: {df.columns.tolist()}")
        # Remove leading/trailing whitespace and potentially leading/trailing symbols like '*'
        df.columns = [re.sub(r'^[\s*]+|[\s*]+$', '', col).strip() for col in df.columns]
        print(f"Cleaned CSV Columns: {df.columns.tolist()}")

        # --- Data Cleaning ---
        # Drop rows where ALL values are NaN (often created by extra separators)
        df = df.dropna(how='all')
        print(f"Shape after dropping all-NaN rows: {df.shape}")

        # Filter based on the 'Note' column if it exists and seems valid
        if "Note" in df.columns:
            # Convert Note column to string to handle potential mixed types safely
            df["Note"] = df["Note"].astype(str).str.strip()
            print(f"--- 'Note' Column Before Filtering (Unique Values) ---\n{df['Note'].unique()}") # Log unique values

            # Make the check case-insensitive for robustness
            df_filtered = df[df["Note"].str.lower().isin(['normal', 'borderline', 'concerning'])]
            print(f"--- DataFrame After Note Filtering (Shape) ---: {df_filtered.shape}") # Log shape after filter
            df = df_filtered # Assign back the filtered df
        else:
            print("Warning: 'Note' column not found or invalid in CSV. Skipping Note-based filtering.")

        # --- Optional: Value Column Cleaning ---
        # If 'Value' column exists, try converting to numeric where possible
        if "Value" in df.columns:
            # Keep original 'Value' for display, create a numeric version for potential calcs/plots
            df['Value_Numeric'] = pd.to_numeric(df['Value'], errors='coerce')
            print(f"--- Value_Numeric created. NaN count: {df['Value_Numeric'].isna().sum()} ---")
            # Handle non-numeric placeholders like '<5' or '>100' if needed
            # Example: df['Value_Numeric'] = df['Value'].str.extract(r'(\d+\.?\d*)')[0].astype(float)
        else:
             print("Warning: 'Value' column not found in CSV.")

        print(f"--- Final Cleaned CSV (Head) ---\n{df.head()}")
        print(f"--- CSV Cleaning Finished. Final Shape: {df.shape} ---")
        return df

    except pd.errors.EmptyDataError:
        print(f"Warning: CSV file '{file_path}' is empty or contains no data after header.")
        return pd.DataFrame()
    except FileNotFoundError:
         print(f"Error: CSV file not found at '{file_path}'")
         return pd.DataFrame()
    except Exception as e:
        print(f"Error cleaning CSV file '{file_path}': {e}")
        traceback.print_exc()
        return pd.DataFrame() # Return empty DataFrame on other errors

# --- END OF FILE utils.py ---